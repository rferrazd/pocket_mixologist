{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install devtools --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Medical Assistant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINICAO DE ROTA -- FAZER ISSO NO JAVA / TYPE SCRIPT\n",
    "\n",
    "Assistente medico genAI tem que decidir e auxiliar para dois scenarios: Emergencial e Diagnostico Diferencial.\n",
    "\n",
    "Dado o estado de um paciente, ex: dor no peito, calafrio, confusao mental. O assistente tem que decidir se deveria, rotear para a sugestao (state) emergencial ou diagnostico diferencial. \n",
    "\n",
    "O Assiste deve saber quando a descrição do usuario é sobre algo que pode estar descrevendo uma doença/fatalidade que pode ocorrer naquele momento, ou uma doença/condicao que precisa de trato imediate ou se o usuario este perguntando,fazendo uma busca sobre um diagnostico diferencial.\n",
    "\n",
    "Essa applicação tera 3 prompts:\n",
    "      1. Prompt Rotear se deveramos ir pro state emergencial, pro state diagnostico diferencial, ou usar o tool AskHuman. \n",
    "      2. Prompt quando estiver no state emergencial.\n",
    "      3. Prompt pra quando no state diagnostico differencial.\n",
    "\n",
    "Explicação dos States\n",
    "1. emergencial\n",
    "      - Dado o estado do paciente, o assistente pode, por exemplo, \n",
    "      sugerir um pronto atendimento. ex: dor no peito, calafrio, confusao mental. Pode ser infarto.entao sugerir a internacao ou procedimento etc.. \n",
    "      - Quando neste state (emergencial) a meta é sugerir algo para ser tomado com um certa urgencia, por isso o nome do state é emergencial.\n",
    "\n",
    "2. diagnostico diferencial\n",
    "      - baseado numa descricao (text) do estado do paciente, investigar a causa.\n",
    "      - Esse sate eh mais pra buscar causas\n",
    "\n",
    "Explicação do tool AskHuman:\n",
    "- Se existe duvidas sobre a descrição do paciente, o LLM deve perguntar mais pro usuario para entender sua descrição e decidir pra qual state ir (emergencial ou diagnostico diferencial)\n",
    "\n",
    "\n",
    "ROUTER_PROMPT:\n",
    "- se o input do usuario nao eh claro, perguntar pro usuario se é emergencia ou diagnostico differencial.\n",
    "- Caso de ambiguidade sobre quais decisoes tomar: \n",
    "      - algo mais emergencial \n",
    "      - busca investigacao \n",
    "\n",
    "\n",
    "- Human in the loop para:\n",
    "      - clarificacao ou confirmacao (confirmacao so pra fins de aprender)\n",
    "      - confirmacao seria mais pra processos de arvore de decisao\n",
    "\n",
    "TESTER API do MEMED.\n",
    "- supondo que .... gerar a receita.\n",
    "- comeca a testar com o postman\n",
    "\n",
    "\n",
    "BULARIO\n",
    "- se puxar 20 remedios, como ele vai mostrar a informacao? uma tabela? \n",
    "- batch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal, Optional\n",
    "from datetime import datetime\n",
    "from devtools import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "load_dotenv()  # Load environment variables from the .env file\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGSMITH_TRACING'] = os.getenv('LANGSMITH_TRACING')\n",
    "os.environ['LANGSMITH_ENDPOINT'] = os.getenv('LANGSMITH_ENDPOINT')\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGSMITH_PROJECT'] = os.getenv('LANGSMITH_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DECISION_OPTIONS = {\"emergencial\", \"diagnostico_diferencial\", \"ask_human\"}\n",
    "\n",
    "class RouterResponse(BaseModel):\n",
    "    decision: Literal[\"emergencial\", \"diagnostico_diferencial\", \"ask_human\", \"\"] = Field(\n",
    "        description=\"Decisão sobre qual caminho seguir com base na descrição do paciente\"\n",
    "    )\n",
    "    case_synthesis: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Síntese técnica do caso a ser analisado\"\n",
    "    )\n",
    "    question_to_human: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Pergunta específica para o usuário quando há necessidade de esclarecimento\"\n",
    "    )\n",
    "    decision_reason: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Explicação pela qual a decisão emergencial, diagnostico_diferencial, ask_human foi feita.\"\n",
    "    )\n",
    "\n",
    "# State\n",
    "class State(MessagesState):\n",
    "      initial_human_input: Optional[str]\n",
    "      decision: Literal[\"emergencial\", \"diagnostico_diferencial\", \"ask_human\", \"\"] \n",
    "      case_synthesis: Optional[str]\n",
    "      question_to_human: Optional[str] \n",
    "      final_answer: Optional[str]\n",
    "      \n",
    "# Model\n",
    "model = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "model = model.with_structured_output(RouterResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emergencial: \n",
    "- Estou com dor no peito que irradia para o braço esquerdo e falta de ar.\n",
    "- Meu filho de 4 anos está com febre alta de 40°C que não baixa com remédios e está muito letárgico.\n",
    "\n",
    "Diagnostico diferencial:\n",
    "- Tenho dor de cabeça frequente nos últimos 3 meses, principalmente de tarde.\n",
    "- Minha pele está ficando amarelada e sinto cansaço constante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTER_PROMPT = \"\"\"Você é um LLM Router em um sistema médico multiagente. Sua função é avaliar se as informações fornecidas pelo usuário (médicos auxiliando pacientes) são SUFICIENTES para tomar uma decisão segura ou se é necessário solicitar mais dados.\n",
    "CONTEXTO DO SISTEMA:\n",
    "Este sistema possui 3 componentes:\n",
    "1. VOCÊ (LLM Router): Responsável por analisar o input do usuário e, com base nas informações coletadas (possivelmente ao longo de várias interações), decidir se o caso precisa ser encaminhado para o Agente Emergencial ou para o Agente de Diagnóstico Diferencial.\n",
    "   **O parâmetro \"case_synthesis\" deve ser atualizado a cada interação, agregando todas as informações coletadas e formando uma síntese técnica clara e completa do caso.**\n",
    "2. Agente Emergencial: Especializado na orientação de casos que demandam atendimento imediato.\n",
    "3. Agente de Diagnóstico Diferencial: Especializado na investigação de condições clínicas que não indiquem urgência imediata.\n",
    "\n",
    "CRITÉRIOS DE INSUFICIÊNCIA DE INFORMAÇÕES:\n",
    "Considere INSUFICIENTES os inputs que:\n",
    "- Sejam menção isolada de um sintoma (ex.: \"dor no peito\", \"febre\", \"dor de cabeça\");\n",
    "- Sejam apenas nomes de doenças sem qualquer contexto (ex.: \"tuberculose\", \"diabetes\");\n",
    "- Sejam descrições vagas (ex.: \"não me sinto bem\", \"estou doente\");\n",
    "- Não contenham detalhes como duração, intensidade ou outros dados clínicos relevantes.  \n",
    "Nesses casos, você DEVE escolher \"ask_human\" e fazer perguntas específicas para obter mais informações.\n",
    "\n",
    "SUA TAREFA ESPECÍFICA:\n",
    "1. Avaliar se o input do usuário contém dados clínicos suficientes para decidir se o caso é emergencial ou se precisa de uma investigação diagnóstica.\n",
    "2. Se as informações forem insuficientes, escolher \"ask_human\" e solicitar detalhes adicionais.\n",
    "3. Se as informações forem suficientes:\n",
    "   - Decidir entre \"emergencial\", se os dados indicarem uma situação de risco imediato (por exemplo, dor torácica com irradiação, dispneia e outros sinais de alerta);\n",
    "   - Ou \"diagnostico_diferencial\", se os dados permitirem uma investigação diagnóstica sem indicar emergência.\n",
    "4. **Caso haja múltiplas interações para esclarecer o problema:**  \n",
    "   A cada nova interação com o usuário, você deve atualizar o parâmetro \"case_synthesis\" agregando as novas informações à síntese acumulada. O \"case_synthsesis\" deve refletir todas as informações obtidas até o momento. Ao final do processo, quando você decidir entre \"emergencial\" ou \"diagnostico_diferencial\", o campo \"case_synthesis\" deverá conter a síntese completa e atualizada de todo o caso, servindo como um briefing claro e preciso para o próximo agente.\n",
    "   \n",
    "   Essa síntese técnica deve:\n",
    "   - Incluir dados relevantes fornecidos pelo usuário (sintomas, duração, intensidade, evolução, etc.);\n",
    "   - Refletir de forma objetiva o entendimento acumulado do caso;\n",
    "   - Servir como um briefing claro e preciso para o próximo agente (emergencial ou diagnóstico diferencial).\n",
    "\n",
    "PARÂMETROS DA SUA RESPOSTA:\n",
    "- \"decision\": Sua decisão final (\"emergencial\", \"diagnostico_diferencial\" ou \"ask_human\").\n",
    "- \"case_synthesis\": Deve ser preenchido ao longo da interação com o usuário e quando a decisão não for \"ask_human\".  \n",
    "  Para casos encaminhados, ele consiste em uma síntese técnica que combina todas as informações relevantes coletadas no caso, permitindo que o próximo agente entenda o contexto clínico e as razões que fundamentaram a decisão.\n",
    "- \"question_to_human\": Pergunta(s) específica(s) para obter mais informações, a ser utilizado quando a decisão for \"ask_human\".\n",
    "- \"decision_reason\": Justificativa para sua decisão, indique se as informações foram suficientes ou não e explicar quais dados faltaram, se for o caso.\n",
    "\n",
    "EXEMPLOS CORRETOS:\n",
    "\n",
    "INPUTS INSUFICIENTES:\n",
    "Exemplo 1:  \n",
    "Input: \"Dor no peito\"  \n",
    "Resposta:\n",
    "{\n",
    "  \"decision\": \"ask_human\",\n",
    "  \"case_synthesis\": \"Dor no peito\",\n",
    "  \"question_to_human\": \"Para avaliar melhor, por favor informe: há quanto tempo o paciente sente essa dor? Ela irradia para braço ou mandíbula? Há outros sintomas, como falta de ar ou náuseas?\",\n",
    "  \"decision_reason\": \"Informações insuficientes. 'Dor no peito' isolada não permite avaliar gravidade sem dados adicionais sobre duração, irradiação e sintomas associados.\"\n",
    "}\n",
    "\n",
    "Exemplo 2:  \n",
    "Input: \"Tuberculose\"  \n",
    "Resposta:\n",
    "{\n",
    "  \"decision\": \"ask_human\",\n",
    "  \"case_synthesis\": \"Tuberculose\",\n",
    "  \"question_to_human\": \"O termo 'tuberculose' foi informado isoladamente. Por favor, forneça mais detalhes: quais sintomas o paciente apresenta, há quanto tempo, presença de tosse, febre ou perda de peso?\",\n",
    "  \"decision_reason\": \"Input insuficiente. 'Tuberculose' sem contexto não permite determinar se o caso é uma suspeita, dúvida diagnóstica ou confirmação.\"\n",
    "}\n",
    "\n",
    "INPUTS SUFICIENTES:\n",
    "Exemplo 3:  \n",
    "Input: \"Dor no peito intensa há 30 minutos que irradia para o braço esquerdo, com falta de ar e suor frio.\"  \n",
    "Resposta:\n",
    "{\n",
    "  \"decision\": \"emergencial\",\n",
    "  \"case_synthesis\": \"Paciente com dor torácica intensa iniciada há 30 minutos, com irradiação para o braço esquerdo, associada à dispneia e diaforese, compatível com um quadro de síndrome coronariana aguda.\",\n",
    "  \"question_to_human\": \"\",\n",
    "  \"decision_reason\": \"As informações fornecidas são suficientes para indicar uma emergência devido ao conjunto de sinais clínicos presentes.\"\n",
    "}\n",
    "\n",
    "Exemplo 4 (com múltiplas interações):  \n",
    "Durante a conversa, foram coletados os seguintes dados do paciente:\n",
    "- Primeira interação: \"Paciente com dor de cabeça.\"\n",
    "   - parametro \"case_synthesis\": \"Paciente com dor de cabeça.\"\n",
    "- Segunda interação: \"É uma dor frontal que vem há 3 meses.\"\n",
    "   - parametro \"case_synthesis\": \"Paciente com dor de cabeça frontal há 3 meses.\" \n",
    "- Terceira interação (após questionamento adicional): \"Não há náuseas ou alterações visuais, mas a dor piora à tarde.\"\n",
    "   - parametro \"case_synthesis\": \"Síntese acumulada: Inicialmente relatada dor de cabeça inespecífica, evoluindo para uma dor frontal persistente há 3 meses, sem sinais de alarme (como náuseas ou alterações visuais) e com piora à tarde.\"\n",
    "Resposta final:\n",
    "{\n",
    "  \"decision\": \"diagnostico_diferencial\",\n",
    "  \"case_synthesis\": \"Síntese acumulada: Inicialmente relatada dor de cabeça inespecífica, evoluindo para uma dor frontal persistente há 3 meses, sem sinais de alarme (como náuseas ou alterações visuais) e com piora à tarde.\",\n",
    "  \"question_to_human\": \"\",\n",
    "  \"decision_reason\": \"As informações acumuladas ao longo das interações são suficientes para orientar um diagnóstico diferencial, embora não indiquem risco imediato.\"\n",
    "}\n",
    "\n",
    "LEMBRE-SE: Caso haja qualquer dúvida sobre a suficiência das informações fornecidas pelo usuário, escolha a opção \"ask_human\". Utilize \"ask_human\" no máximo 3 vezes.\n",
    "\n",
    "Agora, analise o caso apresentado pelo usuário:\n",
    "\"\"\"\n",
    "EMERGENCIAL_PROMPT = \"\"\"Você é um especialista médico. Avalie o caso emergencial para: {input}\n",
    "\n",
    "Objetivo:\n",
    "Oferecer orientações urgentes e baseadas em evidências.\n",
    "\n",
    "Instruções:\n",
    "1. Avaliação: Identifique a condição emergencial provável.\n",
    "2. Protocolo: Recomende a ativação imediata do SAMU (192), especifique a janela terapêutica e o nível do hospital necessário.\n",
    "3. Intervenções: Sugira posicionamento, monitoramento de sinais vitais (e.g., FC, PA, O₂) e suporte pré-hospitalar.\n",
    "4. Contraindicações: Aponte procedimentos e medicações a evitar.\n",
    "5. Critérios de Gravidade: Destaque sinais que indiquem deterioração e necessidade de ação urgente.\n",
    "\n",
    "Utilize terminologia médica precisa, baseando-se em protocolos atualizados (ACLS, ATLS, AHA) e adapte as instruções conforme o público (profissionais ou leigos).\n",
    "\"\"\"\n",
    "\n",
    "DIAGNOSTICO_DIFERENCIAL_PROMPT = \"\"\"Você é um especialista médico. Avalie o diagnóstico diferencial para: {input}\n",
    "Instruções:\n",
    "1. SÍNTESE: Resuma os dados clínicos principais.\n",
    "2. DIAGNÓSTICOS: Liste 3–5 causas (por ordem de probabilidade), detalhando mecanismo, relação com o caso e sinais de alerta.\n",
    "3. INVESTIGAÇÃO: Sugira exames (laboratoriais/imagem) e avaliações especializadas.\n",
    "4. RECOMENDAÇÕES: Indique orientações não medicamentosas e critérios para atendimento urgente.\n",
    "\n",
    "Regras:\n",
    "- Use linguagem técnica e clara.\n",
    "- Não prescreva medicamentos.\n",
    "- Baseie sua análise em evidências clínicas atualizadas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global INTERACTION_COUNT\n",
    "INTERACTION_COUNT = 0\n",
    "# NODES\n",
    "# LLM router\n",
    "def llm_router(state: State):\n",
    "      if state[\"messages\"] and state[\"messages\"][-1].type == \"human\":\n",
    "            human_input = state[\"messages\"][-1].content\n",
    "            print(\"\\nHuman input: \", human_input)\n",
    "\n",
    "            response = model.invoke(state[\"messages\"])\n",
    "\n",
    "            print(\"THIS IS THE ROUTER RESPONSE:\")\n",
    "            pprint(response)\n",
    "            \n",
    "            state[\"decision\"] = response.decision\n",
    "            state[\"question_to_human\"] = response.question_to_human\n",
    "            state[\"case_synthesis\"] = response.case_synthesiss\n",
    "            print(\"Added response to state:\")\n",
    "            print(\"Decision:\", state[\"decision\"])\n",
    "            print(\"Question to Human:\", state[\"question_to_human\"])\n",
    "            print(\"Case Synthesis:\", state[\"case_synthesis\"])\n",
    "\n",
    "            # Add the next question to human or case_synthesis to the chat history\n",
    "            if response.question_to_human and response.decision == \"ask_human\":\n",
    "                 state[\"messages\"].append(AIMessage(content=response.question_to_human))\n",
    "            else:\n",
    "                 state[\"messages\"].append(AIMessage(content=response.case_synthesis))\n",
    "\n",
    "      else:\n",
    "            raise ValueError(\"Expected a human message in state['messages'].\")\n",
    "\n",
    "      return state\n",
    "\n",
    "\n",
    "\n",
    "# Emergencial\n",
    "def emergencial(state: State):\n",
    "      global INTERACTION_COUNT\n",
    "      print('INSIDE EMERGENCIAL')\n",
    "      if state[\"case_synthesis\"]:\n",
    "            input = state[\"case_synthesis\"]\n",
    "            print(f\"Using case_synthesis: {input}\")\n",
    "      else:\n",
    "            input = next((msg for msg in reversed(state[\"messages\"]) if msg.type == \"ai\"), state[\"messages\"][1:])\n",
    "            print(f\"Falling back on the last message from the LLM router: {input}\")\n",
    "\n",
    "      response = ChatOpenAI(model=\"gpt-4o-mini\").invoke(EMERGENCIAL_PROMPT.format(input=input))\n",
    "      state[\"final_answer\"] = response.content\n",
    "      # Add final answer to the chat history\n",
    "      state[\"messages\"].append(AIMessage(content=response.content))\n",
    "      # Reset count\n",
    "      INTERACTION_COUNT = 0 \n",
    "      \n",
    "      return state\n",
    "\n",
    "# Diagnositico Diferencial\n",
    "def diagnostico_diferencial(state: State):\n",
    "      global INTERACTION_COUNT\n",
    "      print(\"INSIDE DIAGNOSTICO DIFERENCIAL\")\n",
    "      if state[\"case_synthesis\"]:\n",
    "            input = state[\"case_synthesis\"]\n",
    "            print(f\"Using case_synthesis: {input}\")\n",
    "      else:\n",
    "            input = next((msg for msg in reversed(state[\"messages\"]) if msg.type == \"ai\"), state[\"messages\"][1:])\n",
    "            print(f\"Falling back on the last message from the LLM router: {input}\")\n",
    "      \n",
    "      response = ChatOpenAI(model=\"gpt-4o-mini\").invoke(DIAGNOSTICO_DIFERENCIAL_PROMPT.format(input=input))\n",
    "      state[\"final_answer\"] = response.content\n",
    "      # Add final answer to the chat history\n",
    "      state[\"messages\"].append(AIMessage(content=response.content))\n",
    "\n",
    "      # Reset count\n",
    "      INTERACTION_COUNT = 0 \n",
    "      \n",
    "      return state\n",
    "\n",
    "# Human Node\n",
    "def ask_human(state: State):\n",
    "      print(\" INSIDE ask_human node\")\n",
    "      question = state[\"question_to_human\"]\n",
    "\n",
    "      if state[\"messages\"]:\n",
    "          if not(state[\"messages\"][-1].type == \"ai\"):\n",
    "              #last_question = state[\"messages\"][-1].content\n",
    "              print(\"Warning: Last message to be asked to human is not of type 'ai'\")\n",
    "      else:\n",
    "          print(\"Warning: No messages available in the state. Retaining original question value:\", question)\n",
    "\n",
    "      user_input = interrupt(value=question)     \n",
    "      \n",
    "      return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"human\",\n",
    "                    \"content\": user_input,\n",
    "                }\n",
    "            ]\n",
    "            }\n",
    "        ,\n",
    "        goto=\"llm_router\",\n",
    "    )\n",
    "\n",
    "# Conditional edge:\n",
    "def router(state: State):\n",
    "    global INTERACTION_COUNT\n",
    "    decision = state.get(\"decision\")\n",
    "    if not isinstance(decision, str):\n",
    "        raise ValueError(f\"state['decision'] must be a string, but got {decision} of type {type(decision).__name__}\")\n",
    "    \n",
    "    if decision not in VALID_DECISION_OPTIONS:\n",
    "        raise ValueError(f\"state['decision'] must be one of {VALID_DECISION_OPTIONS}, but got '{decision}'\")\n",
    "    \n",
    "    if INTERACTION_COUNT >= 3:\n",
    "         print(\"\\n\\n ****Warning: interaction number greater than 4, routing to emergencial**** \\n\\n\")\n",
    "         return \"emergencial\"\n",
    "    \n",
    "    elif decision == \"ask_human\":\n",
    "        INTERACTION_COUNT += 1 \n",
    "        print(f\"INSIDE ROUTER selected ask_human.\\nINTERACTION COUNT: {INTERACTION_COUNT}\")\n",
    "        return \"ask_human\"\n",
    "    elif decision == \"diagnostico_diferencial\":\n",
    "        print(\"INSIDE ROUTER selected \\\"diagnostico_diferencial\\\"\")\n",
    "        return \"diagnostico_diferencial\"\n",
    "    elif decision == \"emergencial\":\n",
    "        print(\"INSIDE ROUTER selected \\\"emergencial\\\"\")\n",
    "        return \"emergencial\"\n",
    "    \n",
    "\n",
    "# BUILD THE GRAPH\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"ask_human\", ask_human)\n",
    "workflow.add_node(\"llm_router\", llm_router)  \n",
    "workflow.add_node(\"diagnostico_diferencial\", diagnostico_diferencial)\n",
    "workflow.add_node(\"emergencial\", emergencial)\n",
    "\n",
    "workflow.add_edge(START, \"llm_router\")\n",
    "workflow.add_edge(\"ask_human\", \"llm_router\")\n",
    "workflow.add_edge(\"diagnostico_diferencial\", END)\n",
    "workflow.add_edge(\"emergencial\", END)\n",
    "workflow.add_conditional_edges(\"llm_router\", router)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testando casos ambiguos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ambiguous_inputs = [\n",
    "      #\"Tuberculose\",\n",
    "      #\"Dor no peito\",\n",
    "      #\"Paciente com febre\",\n",
    "      #\"Muita dor de ouvido e ansiedade\",\n",
    "      #\"Tenho dor de cabeça há dois dias.\"\n",
    "      \"Melanoma\",\n",
    "      #\"Dor de barriga e vomito\"\n",
    "]\n",
    "\n",
    "emergencial_cases = [\n",
    "      \n",
    "#     # \"Dor torácica intensa iniciada há 20 minutos, irradiando para o braço esquerdo, com dispneia e sudorese profusa.\", # OK\n",
    "#     #\"Início súbito de fraqueza em um lado do corpo, dificuldade para falar e perda de equilíbrio.\", # OK\n",
    "     \"Crise asmática com dificuldade respiratória, chiado intenso, cianose e incapacidade de falar\", # OK\n",
    "#     # \"Reação alérgica com inchaço da face e lábios, dificuldade para respirar e sensação de desmaio após exposição a um alérgeno conhecido.\", # OK\n",
    "#     #\"Dor abdominal intensa acompanhada de hipotensão, palidez e sudorese.\" # OK\n",
    "\n",
    " ]\n",
    "\n",
    "diagnostico_diferencial_cases = [\n",
    "    #  \"Cefaleia frontal recorrente há meses, sem piora súbita ou sintomas neurológicos associados.\", # OK\n",
    "    #   \"Dor lombar persistente por várias semanas, sem irradiação ou sinais de compressão medular.\", # OK\n",
    "    #   \"Desconforto torácico leve e intermitente, sem irradiação ou dispneia aguda, com duração de dias.\", # OK\n",
    "    #   \"Episódios intermitentes de tontura e vertigem leves, sem perda súbita de força ou alterações visuais.\", # OK\n",
    "    #   \"Enxaqueca com aura, acompanhada de dor de cabeça intensa, fotofobia e sintomas visuais, persistindo por horas e melhorando com analgésicos.\" # OK\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# poucas palavras, bem vago. \n",
    "# Exemplos:\n",
    "#    - Dor no Peito\n",
    "#   - Tuberculose\n",
    "# UI em typescript --> https://github.com/intellidoctor/assistant-ui\n",
    "    # Depois pluga neste UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(app))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, input in enumerate(ambiguous_inputs):\n",
    "i = 1\n",
    "print(f\"\\n______***_____ CASO TESTE {i} ______***_____ \\n\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": f\"thread_{i}\"}}\n",
    "for event in app.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"system\",\n",
    "                ROUTER_PROMPT\n",
    "            ),\n",
    "            (\n",
    "                \"user\",\n",
    "                ambiguous_inputs[0],  \n",
    "            )\n",
    "        ],\n",
    "        \"initial_human_input\": ambiguous_inputs[0]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in app.stream(Command(resume=\"LOCALização na batata da perna\"), config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    print('+++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).values[\"messages\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in app.stream(Command(resume=\"dias\"), config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    print('+++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in app.stream(Command(resume=\"sim mudanças na aparencia\"), config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    print('+++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in app.stream(Command(resume=\"febre meio alta\"), config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    print('+++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in app.stream(Command(resume=\"sintomas\"), config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    print('+++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
